{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Real or Not using CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3zlIJxO9P5d"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foGbYL2g9QEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79739e04-45d3-43fb-a014-f9fa52abe657"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import spacy\r\n",
        "import torch.nn as nn\r\n",
        "import torch\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch.optim as optim\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "from sklearn.metrics import roc_curve, auc\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import math\r\n",
        "\r\n",
        "from torch.nn.utils.rnn import pad_sequence \r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "\r\n",
        "import random\r\n",
        "import time\r\n",
        "import re\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doUXTiXx9mgC",
        "outputId": "8db46c35-bb39-4fb7-f473-575b6b81c26b"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIs6WQ-sU_gm"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9fdHbiS-Jqx"
      },
      "source": [
        "PATH_TRAIN = '/content/drive/MyDrive/NLP - Real or Not/train.csv'\r\n",
        "PATH_VAL = '/content/drive/MyDrive/NLP - Real or Not/val.csv'\r\n",
        "PATH_TEST = '/content/drive/MyDrive/NLP - Real or Not/test.csv'\r\n",
        "PATH_SUB = '/content/drive/MyDrive/NLP - Real or Not/sample_submission.csv'\r\n",
        "OUTPUT = '/content/drive/MyDrive/NLP - Real or Not/submission.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9BJYqXFU-xr"
      },
      "source": [
        "params = {\r\n",
        "    'LR': 3e-4,\r\n",
        "    'N_EPOCHS': 20,\r\n",
        "    'BATCH_SZ': 32,\r\n",
        "    'PAD_INDEX': 0,\r\n",
        "    'N_VOCAB': 4000\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td2Eq4Y9RRI5"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKezH5jJ4rtr"
      },
      "source": [
        "  def remove_abbreviations(text):\r\n",
        "    text = text.lower()\r\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\r\n",
        "    text = re.sub(r\"you'll\", \"you will\", text)\r\n",
        "    text = re.sub(r\"i'll\", \"i will\", text)\r\n",
        "    text = re.sub(r\"she'll\", \"she will\", text)\r\n",
        "    text = re.sub(r\"he'll\", \"he will\", text)\r\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\r\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\r\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\r\n",
        "    text = re.sub(r\"what's\", \"what is\", text)\r\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\r\n",
        "    text = re.sub(r\"there's\", \"there is\", text)\r\n",
        "    text = re.sub(r\"here's\", \"here is\", text)\r\n",
        "    text = re.sub(r\"who's\", \"who is\", text)\r\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\r\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\r\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\r\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\r\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\r\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\r\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\r\n",
        "    text = re.sub(r\"don't\", \"do not\", text)\r\n",
        "    text = re.sub(r\"shouldn't\", \"should not\", text)\r\n",
        "    text = re.sub(r\"n't\", \" not\", text)\r\n",
        "    text = re.sub(r'\\s+', \" \", text)\r\n",
        "\r\n",
        "    return text\r\n",
        "  \r\n",
        "  def text_preprocessing(text):\r\n",
        "    \"\"\"\r\n",
        "    - Remove entity mentions (eg. '@united')\r\n",
        "    - Correct errors (eg. '&amp;' to '&')\r\n",
        "    @param    text (str): a string to be processed.\r\n",
        "    @return   text (Str): the processed string.\r\n",
        "    \"\"\"\r\n",
        "    # Initializing the Lemmatizer\r\n",
        "    lem = WordNetLemmatizer()\r\n",
        "\r\n",
        "    # Remove '@name'\r\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\r\n",
        "\r\n",
        "    # Replace '&amp;' with '&'\r\n",
        "    text = re.sub(r'&amp;', '&', text)\r\n",
        "\r\n",
        "    # Remove trailing whitespace\r\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\r\n",
        "\r\n",
        "    # Remove common abbreviations\r\n",
        "    text = remove_abbreviations(text)\r\n",
        "\r\n",
        "    text = text.split()\r\n",
        "\r\n",
        "    text = [lem.lemmatize(word) for word in text if word not in set(stopwords.words('english'))]\r\n",
        "    text = [word for word in text if word not in set(stopwords.words('english'))]\r\n",
        "    text = ' '.join(text)\r\n",
        "    text = text.split()\r\n",
        "\r\n",
        "    return text\r\n",
        "\r\n",
        "\r\n",
        "def build_word2idx(train_path, n_vocab = 4000):\r\n",
        "    df = pd.read_csv(train_path)\r\n",
        "    text = df['text']\r\n",
        "    words_count = {}\r\n",
        "\r\n",
        "    for sent in text:\r\n",
        "      sent_toks = text_preprocessing(sent)\r\n",
        "\r\n",
        "      for tok in sent_toks:\r\n",
        "        if tok not in words_count:\r\n",
        "          words_count[tok] = 1\r\n",
        "\r\n",
        "        else: words_count[tok] += 1\r\n",
        "\r\n",
        "    word2idx = {'<PAD>':0, '<UNK>':1}\r\n",
        "    idx = 2\r\n",
        "    \r\n",
        "    words_count = sorted(words_count.items(), key=lambda x: x[1], reverse=True)\r\n",
        "    top_words = [w for w, count in words_count[:n_vocab-1]]\r\n",
        "\r\n",
        "    for w in top_words:\r\n",
        "      word2idx[w] = idx\r\n",
        "      idx += 1\r\n",
        "    \r\n",
        "    return word2idx\r\n",
        "\r\n",
        "def tokenizer_en(text):\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qrSnE7BRazK"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QvP4cLj4B-p"
      },
      "source": [
        "class DisasterTweets(Dataset):\r\n",
        "  def __init__(self, file_path, word2idx, istest=False):\r\n",
        "    super(DisasterTweets,self).__init__()\r\n",
        "    self.df = pd.read_csv(file_path)\r\n",
        "    self.id = self.df['id']\r\n",
        "    self.text = self.df[\"text\"]\r\n",
        "    self.word2idx = word2idx\r\n",
        "\r\n",
        "    if istest == False :\r\n",
        "      self.label = self.df[\"target\"]\r\n",
        "    \r\n",
        "    else: self.label = [0]*len(self.df)\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.df)\r\n",
        "  \r\n",
        "  def __getitem__(self, index):\r\n",
        "    txt = self.text[index]\r\n",
        "    lab = self.label[index]\r\n",
        "    id = self.id[index]\r\n",
        "    tok_sent = text_preprocessing(txt)\r\n",
        "    tok_ids = [self.word2idx[token] if token in self.word2idx else 1 for token in tok_sent]\r\n",
        "\r\n",
        "    return lab, torch.tensor(tok_ids,dtype = torch.long), id"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b13HGYcg4w9i"
      },
      "source": [
        "class MyCollate:\r\n",
        "  def __init__(self, pad_idx):\r\n",
        "    self.pad_idx = pad_idx\r\n",
        "\r\n",
        "  def __call__(self, batch):\r\n",
        "    label = [item[0] for item in batch]\r\n",
        "    id = [item[2] for item in batch]\r\n",
        "    tok_ids = [item[1] for item in batch]\r\n",
        "    tok_ids = pad_sequence(sequences=tok_ids, batch_first = False, padding_value = self.pad_idx)\r\n",
        "\r\n",
        "    return  tok_ids, label, id"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwOlax9r510_"
      },
      "source": [
        "def get_loader(\r\n",
        "    annotation_file,\r\n",
        "    word2idx,\r\n",
        "    batch_size=32,\r\n",
        "    num_workers = 0,\r\n",
        "    shuffle = True,\r\n",
        "    pin_memory = True,\r\n",
        "    istest=False):\r\n",
        "  \r\n",
        "  pad_index = params['PAD_INDEX']\r\n",
        "  \r\n",
        "  dataset = DisasterTweets(annotation_file,word2idx,istest=istest)\r\n",
        "\r\n",
        "  loader = DataLoader(\r\n",
        "      dataset =dataset,\r\n",
        "      batch_size = batch_size,\r\n",
        "      num_workers = num_workers,\r\n",
        "      shuffle = shuffle,\r\n",
        "      pin_memory = pin_memory,\r\n",
        "      collate_fn = MyCollate(pad_idx=pad_index)\r\n",
        "  )\r\n",
        "\r\n",
        "  return loader, dataset"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyZ1dOCnEFe_"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dZHpCkwOBnf"
      },
      "source": [
        "# Positional encoding from Pytorch website\r\n",
        "\r\n",
        "class PositionalEncoding(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\r\n",
        "        super(PositionalEncoding, self).__init__()\r\n",
        "        self.dropout = nn.Dropout(p=dropout)\r\n",
        "\r\n",
        "        pe = torch.zeros(max_len, d_model)\r\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\r\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\r\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\r\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\r\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\r\n",
        "        self.register_buffer('pe', pe)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = x + self.pe[:x.size(0), :]\r\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz6N7i5Bg8JJ"
      },
      "source": [
        "# Model with extra layers on top of RoBERTa\r\n",
        "class CBOWClassifier(torch.nn.Module):\r\n",
        "    def __init__(self, n_vocab, embedding_sz, dropout_rate=0.4, n_hidden = 20):\r\n",
        "        super(CBOWClassifier, self).__init__() \r\n",
        "        self.pos_encoder = PositionalEncoding(embedding_sz, dropout_rate)\r\n",
        "        self.embedding = nn.Embedding(n_vocab, embedding_sz, padding_idx=0)\r\n",
        "        self.d1 = nn.Dropout(dropout_rate)\r\n",
        "        self.l2 = nn.Linear(n_hidden, 2)\r\n",
        "        self.l1 = nn.Linear(embedding_sz, n_hidden)\r\n",
        "        \r\n",
        "    def forward(self, tweet):\r\n",
        "        x = self.embedding(tweet)\r\n",
        "        x = self.pos_encoder(x)\r\n",
        "        x = x.mean(dim=0)\r\n",
        "        x = self.d1(x)\r\n",
        "        x = torch.relu(self.l1(x))\r\n",
        "        out = self.l2(x)\r\n",
        "        \r\n",
        "        return out"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf6sKg9_EOxK"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh-yQoLpMDYW"
      },
      "source": [
        "def set_seed(seed_value=42):\r\n",
        "    \"\"\"Set seed for reproducibility.\r\n",
        "    \"\"\"\r\n",
        "    random.seed(seed_value)\r\n",
        "    np.random.seed(seed_value)\r\n",
        "    torch.manual_seed(seed_value)\r\n",
        "    torch.cuda.manual_seed_all(seed_value)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEHT2O-KM4Oz"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "def train_fn(model, train_loader, val_loader, optimizer, word2idx, num_epochs = 5):\r\n",
        "\r\n",
        "      train_loss = 0.0\r\n",
        "      valid_loss = 0.0\r\n",
        "      train_loss_list = []\r\n",
        "      valid_loss_list = []\r\n",
        "      best_valid_loss = float('Inf')\r\n",
        "      \r\n",
        "      global_step = 0\r\n",
        "      global_steps_list = []\r\n",
        "\r\n",
        "      for epoch in range(num_epochs):\r\n",
        "        model.train()\r\n",
        "        for text, label, ids  in train_loader:\r\n",
        "\r\n",
        "          tok_ids = text.to(device)\r\n",
        "          label  = torch.tensor(label).to(device)\r\n",
        "\r\n",
        "          y_pred = model(tok_ids)\r\n",
        "          loss = loss_fn(y_pred, label)\r\n",
        "\r\n",
        "\r\n",
        "          # Back prop\r\n",
        "          loss.backward()\r\n",
        "\r\n",
        "          # Clip to avoid exploding gradient issues, makes sure grads are\r\n",
        "          # within a healthy range\r\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\r\n",
        "\r\n",
        "          optimizer.step()\r\n",
        "\r\n",
        "          optimizer.zero_grad()\r\n",
        "\r\n",
        "          #model.embedding.weight.data[0] = 0\r\n",
        "\r\n",
        "          train_loss += loss.item()\r\n",
        "          global_step += 1\r\n",
        "\r\n",
        "          if global_step%50 == 0:\r\n",
        "            model.eval()\r\n",
        "\r\n",
        "            with torch.no_grad():\r\n",
        "            \r\n",
        "              for text, label, ids in val_loader:\r\n",
        "                  tok_ids = text.to(device)\r\n",
        "                  label = torch.tensor(label).to(device)\r\n",
        "\r\n",
        "                  y_pred = model(tok_ids)\r\n",
        "\r\n",
        "                  loss = loss_fn(y_pred, label)\r\n",
        "                  valid_loss += loss.item()\r\n",
        "\r\n",
        "                \r\n",
        "            # Store train and validation loss history\r\n",
        "            train_loss = train_loss / 50\r\n",
        "            valid_loss = valid_loss / len(val_loader)\r\n",
        "            train_loss_list.append(train_loss)\r\n",
        "            valid_loss_list.append(valid_loss)\r\n",
        "            global_steps_list.append(global_step)\r\n",
        "\r\n",
        "            print('Epoch [{}/{}], global step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\r\n",
        "            .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader), train_loss, valid_loss))\r\n",
        "\r\n",
        "            # checkpoint\r\n",
        "            if best_valid_loss > valid_loss:\r\n",
        "                best_valid_loss = valid_loss\r\n",
        "                \"\"\"\r\n",
        "                save_checkpoint(output_path + '/model.pkl', model, best_valid_loss)\r\n",
        "                save_metrics(output_path + '/metric.pkl', train_loss_list, valid_loss_list, global_steps_list)\r\n",
        "                \"\"\"\r\n",
        "                        \r\n",
        "            train_loss = 0.0                \r\n",
        "            valid_loss = 0.0\r\n",
        "            model.train()\r\n",
        "    \r\n",
        "      \"\"\"save_metrics(output_path + '/metric.pkl', train_loss_list, valid_loss_list, global_steps_list)\"\"\"\r\n",
        "      print('Training done!')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O_EfSULF9Xt"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3AKT6E5Hom8"
      },
      "source": [
        "def evaluate_fn(model, val_loader):\r\n",
        "    y_pred = []\r\n",
        "    y_true = []\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for text, label, ids in val_loader:\r\n",
        "\r\n",
        "            tok_ids = text.to(device)\r\n",
        "                \r\n",
        "            output = model(tok_ids)\r\n",
        "            _, pred = torch.max(output.data, 1)\r\n",
        "\r\n",
        "            y_pred.extend(pred.tolist())\r\n",
        "            y_true.extend(label)\r\n",
        "    \r\n",
        "    print('Classification Report:')\r\n",
        "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\r\n",
        "    \r\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\r\n",
        "    ax = plt.subplot()\r\n",
        "\r\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\r\n",
        "\r\n",
        "    ax.set_title('Confusion Matrix')\r\n",
        "\r\n",
        "    ax.set_xlabel('Predicted Labels')\r\n",
        "    ax.set_ylabel('True Labels')\r\n",
        "\r\n",
        "    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\r\n",
        "    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\r\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHLTb4R-dgNj"
      },
      "source": [
        "def submission(model, test_loader, test, path_sub = PATH_SUB):\r\n",
        "\r\n",
        "  submission = pd.read_csv(PATH_SUB)\r\n",
        "\r\n",
        "  predictions = []\r\n",
        "  ids = []\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "\r\n",
        "    for text, _, id in test_loader:\r\n",
        "      tok_ids = text.to(device)\r\n",
        "      output = model(tok_ids)\r\n",
        "      _, predicted =torch.max(output.data, 1)\r\n",
        "\r\n",
        "      predictions.append(predicted)\r\n",
        "      ids.append(id)\r\n",
        "    \r\n",
        "    predictions = torch.cat(predictions, dim=0)\r\n",
        "\r\n",
        "    submission['id'] = [item for sublist in ids for item in sublist]\r\n",
        "    submission['target'] = predictions.cpu()\r\n",
        "\r\n",
        "  return submission"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhM7dywMGBmG"
      },
      "source": [
        "# Raw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OECMjDGUG1t"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOLCYkZCIWo2"
      },
      "source": [
        "def run():\r\n",
        "\r\n",
        "  n_vocab = params['N_VOCAB']\r\n",
        "  n_epochs = params['N_EPOCHS']\r\n",
        "  batch_sz = params['BATCH_SZ']\r\n",
        "\r\n",
        "  word2idx = build_word2idx(PATH_TRAIN,n_vocab)\r\n",
        "\r\n",
        "  train_loader, train = get_loader(PATH_TRAIN, word2idx,)\r\n",
        "  val_loader, val = get_loader(PATH_VAL, word2idx)\r\n",
        "  test_loader, test = get_loader(PATH_TEST, word2idx, shuffle = False, istest=True)\r\n",
        "\r\n",
        "  #steps_per_epoch = len(train_loader)\r\n",
        "\r\n",
        "  model = CBOWClassifier(4001, 300)\r\n",
        "  model = model.to(device)\r\n",
        "\r\n",
        "  print(\"======================= Start training =================================\")\r\n",
        "  optimizer = optim.Adam(model.parameters(), lr=params['LR'])\r\n",
        "\r\n",
        "  train_fn(model=model, \r\n",
        "        train_loader=train_loader,\r\n",
        "        val_loader=val_loader,\r\n",
        "        optimizer=optimizer,\r\n",
        "        word2idx = word2idx, \r\n",
        "        num_epochs=n_epochs)\r\n",
        "\r\n",
        "\r\n",
        "  evaluate_fn(model = model,\r\n",
        "              val_loader = val_loader)\r\n",
        "\r\n",
        "  \r\n",
        "  sub = submission(model, test_loader, test, path_sub = PATH_SUB)\r\n",
        "\r\n",
        "  return sub"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5ZlpnByKJ4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bf409c3-e25c-4b95-d319-ab99cbd5dbe3"
      },
      "source": [
        "sub = run()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======================= Start training =================================\n",
            "Epoch [1/20], global step [50/3820], Train Loss: 0.6927, Valid Loss: 0.6823\n",
            "Epoch [1/20], global step [100/3820], Train Loss: 0.6866, Valid Loss: 0.6799\n",
            "Epoch [1/20], global step [150/3820], Train Loss: 0.6870, Valid Loss: 0.6795\n",
            "Epoch [2/20], global step [200/3820], Train Loss: 0.6805, Valid Loss: 0.6781\n",
            "Epoch [2/20], global step [250/3820], Train Loss: 0.6811, Valid Loss: 0.6779\n",
            "Epoch [2/20], global step [300/3820], Train Loss: 0.6825, Valid Loss: 0.6750\n",
            "Epoch [2/20], global step [350/3820], Train Loss: 0.6822, Valid Loss: 0.6726\n",
            "Epoch [3/20], global step [400/3820], Train Loss: 0.6814, Valid Loss: 0.6712\n",
            "Epoch [3/20], global step [450/3820], Train Loss: 0.6725, Valid Loss: 0.6698\n",
            "Epoch [3/20], global step [500/3820], Train Loss: 0.6755, Valid Loss: 0.6658\n",
            "Epoch [3/20], global step [550/3820], Train Loss: 0.6700, Valid Loss: 0.6645\n",
            "Epoch [4/20], global step [600/3820], Train Loss: 0.6651, Valid Loss: 0.6605\n",
            "Epoch [4/20], global step [650/3820], Train Loss: 0.6604, Valid Loss: 0.6555\n",
            "Epoch [4/20], global step [700/3820], Train Loss: 0.6615, Valid Loss: 0.6521\n",
            "Epoch [4/20], global step [750/3820], Train Loss: 0.6569, Valid Loss: 0.6490\n",
            "Epoch [5/20], global step [800/3820], Train Loss: 0.6521, Valid Loss: 0.6433\n",
            "Epoch [5/20], global step [850/3820], Train Loss: 0.6468, Valid Loss: 0.6392\n",
            "Epoch [5/20], global step [900/3820], Train Loss: 0.6467, Valid Loss: 0.6351\n",
            "Epoch [5/20], global step [950/3820], Train Loss: 0.6333, Valid Loss: 0.6273\n",
            "Epoch [6/20], global step [1000/3820], Train Loss: 0.6245, Valid Loss: 0.6276\n",
            "Epoch [6/20], global step [1050/3820], Train Loss: 0.6379, Valid Loss: 0.6162\n",
            "Epoch [6/20], global step [1100/3820], Train Loss: 0.6214, Valid Loss: 0.6091\n",
            "Epoch [7/20], global step [1150/3820], Train Loss: 0.6165, Valid Loss: 0.6059\n",
            "Epoch [7/20], global step [1200/3820], Train Loss: 0.6066, Valid Loss: 0.5981\n",
            "Epoch [7/20], global step [1250/3820], Train Loss: 0.6008, Valid Loss: 0.5948\n",
            "Epoch [7/20], global step [1300/3820], Train Loss: 0.5930, Valid Loss: 0.5868\n",
            "Epoch [8/20], global step [1350/3820], Train Loss: 0.6025, Valid Loss: 0.5905\n",
            "Epoch [8/20], global step [1400/3820], Train Loss: 0.6074, Valid Loss: 0.5800\n",
            "Epoch [8/20], global step [1450/3820], Train Loss: 0.5813, Valid Loss: 0.5724\n",
            "Epoch [8/20], global step [1500/3820], Train Loss: 0.5755, Valid Loss: 0.5705\n",
            "Epoch [9/20], global step [1550/3820], Train Loss: 0.5737, Valid Loss: 0.5664\n",
            "Epoch [9/20], global step [1600/3820], Train Loss: 0.5750, Valid Loss: 0.5623\n",
            "Epoch [9/20], global step [1650/3820], Train Loss: 0.5713, Valid Loss: 0.5616\n",
            "Epoch [9/20], global step [1700/3820], Train Loss: 0.5781, Valid Loss: 0.5539\n",
            "Epoch [10/20], global step [1750/3820], Train Loss: 0.5656, Valid Loss: 0.5577\n",
            "Epoch [10/20], global step [1800/3820], Train Loss: 0.5669, Valid Loss: 0.5468\n",
            "Epoch [10/20], global step [1850/3820], Train Loss: 0.5376, Valid Loss: 0.5480\n",
            "Epoch [10/20], global step [1900/3820], Train Loss: 0.5466, Valid Loss: 0.5409\n",
            "Epoch [11/20], global step [1950/3820], Train Loss: 0.5423, Valid Loss: 0.5372\n",
            "Epoch [11/20], global step [2000/3820], Train Loss: 0.5448, Valid Loss: 0.5369\n",
            "Epoch [11/20], global step [2050/3820], Train Loss: 0.5471, Valid Loss: 0.5331\n",
            "Epoch [11/20], global step [2100/3820], Train Loss: 0.5798, Valid Loss: 0.5320\n",
            "Epoch [12/20], global step [2150/3820], Train Loss: 0.5410, Valid Loss: 0.5295\n",
            "Epoch [12/20], global step [2200/3820], Train Loss: 0.5398, Valid Loss: 0.5306\n",
            "Epoch [12/20], global step [2250/3820], Train Loss: 0.5296, Valid Loss: 0.5310\n",
            "Epoch [13/20], global step [2300/3820], Train Loss: 0.5354, Valid Loss: 0.5273\n",
            "Epoch [13/20], global step [2350/3820], Train Loss: 0.5421, Valid Loss: 0.5253\n",
            "Epoch [13/20], global step [2400/3820], Train Loss: 0.5252, Valid Loss: 0.5201\n",
            "Epoch [13/20], global step [2450/3820], Train Loss: 0.5482, Valid Loss: 0.5302\n",
            "Epoch [14/20], global step [2500/3820], Train Loss: 0.5254, Valid Loss: 0.5333\n",
            "Epoch [14/20], global step [2550/3820], Train Loss: 0.5249, Valid Loss: 0.5196\n",
            "Epoch [14/20], global step [2600/3820], Train Loss: 0.5216, Valid Loss: 0.5126\n",
            "Epoch [14/20], global step [2650/3820], Train Loss: 0.5199, Valid Loss: 0.5126\n",
            "Epoch [15/20], global step [2700/3820], Train Loss: 0.4979, Valid Loss: 0.5227\n",
            "Epoch [15/20], global step [2750/3820], Train Loss: 0.5294, Valid Loss: 0.5126\n",
            "Epoch [15/20], global step [2800/3820], Train Loss: 0.5088, Valid Loss: 0.5069\n",
            "Epoch [15/20], global step [2850/3820], Train Loss: 0.5235, Valid Loss: 0.5089\n",
            "Epoch [16/20], global step [2900/3820], Train Loss: 0.5071, Valid Loss: 0.5064\n",
            "Epoch [16/20], global step [2950/3820], Train Loss: 0.5034, Valid Loss: 0.5178\n",
            "Epoch [16/20], global step [3000/3820], Train Loss: 0.5118, Valid Loss: 0.5065\n",
            "Epoch [16/20], global step [3050/3820], Train Loss: 0.5026, Valid Loss: 0.5049\n",
            "Epoch [17/20], global step [3100/3820], Train Loss: 0.5017, Valid Loss: 0.5043\n",
            "Epoch [17/20], global step [3150/3820], Train Loss: 0.5116, Valid Loss: 0.5107\n",
            "Epoch [17/20], global step [3200/3820], Train Loss: 0.4876, Valid Loss: 0.5131\n",
            "Epoch [18/20], global step [3250/3820], Train Loss: 0.5065, Valid Loss: 0.5016\n",
            "Epoch [18/20], global step [3300/3820], Train Loss: 0.4829, Valid Loss: 0.4994\n",
            "Epoch [18/20], global step [3350/3820], Train Loss: 0.4991, Valid Loss: 0.5008\n",
            "Epoch [18/20], global step [3400/3820], Train Loss: 0.4907, Valid Loss: 0.5029\n",
            "Epoch [19/20], global step [3450/3820], Train Loss: 0.5044, Valid Loss: 0.4984\n",
            "Epoch [19/20], global step [3500/3820], Train Loss: 0.4918, Valid Loss: 0.4963\n",
            "Epoch [19/20], global step [3550/3820], Train Loss: 0.4887, Valid Loss: 0.4967\n",
            "Epoch [19/20], global step [3600/3820], Train Loss: 0.4954, Valid Loss: 0.4931\n",
            "Epoch [20/20], global step [3650/3820], Train Loss: 0.4785, Valid Loss: 0.5184\n",
            "Epoch [20/20], global step [3700/3820], Train Loss: 0.4884, Valid Loss: 0.4905\n",
            "Epoch [20/20], global step [3750/3820], Train Loss: 0.4930, Valid Loss: 0.4922\n",
            "Epoch [20/20], global step [3800/3820], Train Loss: 0.4939, Valid Loss: 0.4970\n",
            "Training done!\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7861    0.6117    0.6880       649\n",
            "           0     0.7525    0.8764    0.8097       874\n",
            "\n",
            "    accuracy                         0.7636      1523\n",
            "   macro avg     0.7693    0.7441    0.7489      1523\n",
            "weighted avg     0.7668    0.7636    0.7579      1523\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ8iSAtxzMOC"
      },
      "source": [
        "sub.to_csv(OUTPUT, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}